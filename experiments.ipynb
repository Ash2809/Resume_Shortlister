{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\a\\envs\\resume\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2 as pdf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\",temperature = 0)\n",
    "\n",
    "print(llm.invoke(\"What is the capital of India\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(path):\n",
    "    reader=pdf.PdfReader(path)\n",
    "    text=\"\"\n",
    "    for page in range(len(reader.pages)):\n",
    "        page=reader.pages[page]\n",
    "        text+=str(page.extract_text())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pdf_to_text(r\"C:\\Projects\\Resume_Shortlister\\data\\My_Resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"Machine Learning(ML),Deep Learning(DL),Generative AI,RAG\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"You are a a skilled or very experience ATS(Application Tracking System)\n",
    "with a deep understanding of tech field,software engineering,data science ,data analyst\n",
    "and big data engineer. Your task is to read the resume and rate it in terms of percentage of keywords \n",
    "matching in the gievn job decription. Description{description} .Resume{text}.answer in terms of percentage only\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'75% \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt1).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"You are a smart ATS(Application Tracking System) with a deep understanding of the job fields.\n",
    "Based on the job description provide some helpfull insights the candidate can add in the resume.Do not \n",
    "answer more than asked and answer professionally.resume{text} description:{description}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Resume Insights for Aashutosh Kumar:\\n\\n**To enhance your resume for Machine Learning, Deep Learning, Generative AI, and RAG roles, consider these additions:**\\n\\n* **Quantify Achievements:**  Instead of stating \"high accuracy\" in the Sign Language Detector project, provide specific metrics like accuracy percentage or F1 score. \\n* **Highlight Specific Skills:**  Expand your \"Skills\" section with more specific ML/DL techniques like:\\n    * **ML:**  Regression, Classification, Clustering, Decision Trees, Random Forests, Gradient Boosting, etc.\\n    * **DL:**  Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs), etc.\\n    * **Generative AI:**  Prompt Engineering, Text Generation, Image Generation, Code Generation, etc.\\n    * **RAG:**  Knowledge Graph Construction, Question Answering, Summarization, etc.\\n* **Project Focus:**  Tailor your project descriptions to emphasize the relevant skills for the specific job you\\'re applying for. For example, if applying for a role focused on RAG, highlight the E-commerce Bot project\\'s integration with a backend database for data management.\\n* **Frame Projects as Solutions:**  Instead of just listing project titles, describe the problem you solved and the impact of your solution. For example, \"Developed a medical chatbot to address the growing need for accessible healthcare information, improving user understanding of symptoms and potential diagnoses.\"\\n* **Add Relevant Certifications:**  Consider obtaining certifications in relevant technologies like AWS Machine Learning, Google Cloud AI Platform, or Microsoft Azure AI.\\n* **Showcase Projects:**  Include links to your projects on platforms like GitHub, Kaggle, or Hugging Face to demonstrate your practical skills.\\n* **Consider a Portfolio:**  Create a dedicated portfolio website to showcase your projects and skills in a more organized and visually appealing way. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt2).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
